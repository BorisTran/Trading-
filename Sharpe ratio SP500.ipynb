{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Sharpe Ratio\n",
    "\n",
    "This notebook has been created for active management of the SP500 ETF. It allowed to maximize the sharpe ratio of all the equities include in the SP500."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T02:04:05.438794Z",
     "start_time": "2025-03-04T02:03:51.207125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "#Step 1: Fetch the S&P 500 tickers\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "table = pd.read_html(url)\n",
    "sp500_tickers = table[0]['Symbol'].tolist()\n",
    "\n",
    "#Fix ticker symbols for Yahoo Finance\n",
    "sp500_tickers = [ticker.replace('.', '-') for ticker in sp500_tickers]\n",
    "\n",
    "#Step 2: Download adjusted closing prices\n",
    "data = yf.download(sp500_tickers, start=\"2020-01-01\", end=\"2025-01-01\")['Close']\n",
    "\n",
    "#Step 3: Clean the data (drop tickers with too many missing values)\n",
    "data = data.dropna(axis=1, thresh=int(len(data) * 0.7))  # Keep only stocks with 70%+ data available\n",
    "\n",
    "#Step 4: Compute daily returns and filter invalid stocks\n",
    "returns = data.pct_change().dropna()\n",
    "\n",
    "#Step 5: Compute annualized return & covariance matrix\n",
    "mean_returns = returns.mean() * 252\n",
    "cov_matrix = returns.cov() * 252\n",
    "\n",
    "#Step 6: Validate the covariance matrix\n",
    "if cov_matrix.isnull().values.any():\n",
    "    print(\"Covariance matrix contains NaN values. Fixing it...\")\n",
    "    cov_matrix = cov_matrix.fillna(0)\n",
    "\n",
    "#Step 7: Ensure valid data before optimization\n",
    "if np.all(mean_returns == 0):\n",
    "    raise ValueError(\"Mean returns are all zeros. Data issue?\")\n",
    "if np.all(cov_matrix == 0):\n",
    "    raise ValueError(\"Covariance matrix is all zeros. Cannot optimize.\")\n",
    "\n",
    "#Step 8: Select the top 100 stocks with the highest mean return\n",
    "top_stocks = mean_returns.nlargest(100).index\n",
    "returns = returns[top_stocks]\n",
    "mean_returns = mean_returns[top_stocks]\n",
    "cov_matrix = cov_matrix.loc[top_stocks, top_stocks]\n",
    "\n",
    "#Step 9: Set up the optimization parameters\n",
    "risk_free_rate = 0.04  # 4% risk-free rate\n",
    "\n",
    "#Define the negative Sharpe ratio function\n",
    "def negative_sharpe(weights, mean_returns, cov_matrix, risk_free_rate):\n",
    "    portfolio_return = np.dot(weights, mean_returns)\n",
    "    portfolio_std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_std\n",
    "    return -sharpe_ratio  # Negative since we minimize\n",
    "\n",
    "#Constraints: Weights sum to 1\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "\n",
    "#Bounds: No short-selling (0% to 100%)\n",
    "bounds = tuple((0, 1) for _ in range(len(top_stocks)))\n",
    "\n",
    "#Step 10: Use an improved initial weight guess (inverse volatility)\n",
    "inv_vol = 1 / returns.std()\n",
    "initial_weights = inv_vol / np.sum(inv_vol)\n",
    "\n",
    "#Step 11: Run the optimization\n",
    "optimized_result = minimize(\n",
    "    negative_sharpe,\n",
    "    initial_weights,\n",
    "    args=(mean_returns, cov_matrix, risk_free_rate),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "#Step 12: Extract and display optimal weights\n",
    "optimal_weights = optimized_result.x\n",
    "print(\"\\nðŸ“Š **Optimized Portfolio Weights:**\")\n",
    "for ticker, weight in sorted(zip(top_stocks, optimal_weights), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{ticker}: {weight:.2%}\")\n",
    "\n",
    "# Step 13: Compute and display final portfolio statistics\n",
    "optimal_return = np.dot(optimal_weights, mean_returns)\n",
    "optimal_volatility = np.sqrt(np.dot(optimal_weights.T, np.dot(cov_matrix, optimal_weights)))\n",
    "optimal_sharpe = (optimal_return - risk_free_rate) / optimal_volatility\n",
    "\n",
    "print(f\"\\n Expected Annual Return: {optimal_return:.2%}\")\n",
    "print(f\" Expected Volatility: {optimal_volatility:.2%}\")\n",
    "print(f\" Optimized Sharpe Ratio: {optimal_sharpe:.2f}\")\n"
   ],
   "id": "a38e2da2a68fb73e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  503 of 503 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š **Optimized Portfolio Weights:**\n",
      "MCK: 18.12%\n",
      "LLY: 15.85%\n",
      "TRGP: 12.61%\n",
      "VST: 8.64%\n",
      "CBOE: 8.26%\n",
      "IRM: 7.89%\n",
      "PGR: 5.18%\n",
      "ORLY: 3.90%\n",
      "AVGO: 3.72%\n",
      "AXON: 3.60%\n",
      "\n",
      " Expected Annual Return: 43.30%\n",
      " Expected Volatility: 16.42%\n",
      " Optimized Sharpe Ratio: 2.39\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "988523171a3be2ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
